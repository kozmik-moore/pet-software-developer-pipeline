{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d87ea02-5b59-46e0-b59e-b6801142bab2",
   "metadata": {},
   "source": [
    "# Data Engineer Certification Sample Practical Exam\n",
    "\n",
    "HappyPaws, creates fun and educational apps for pet owners. \n",
    "\n",
    "HappyPaws wants to help pet owners understand their pets better by tracking their activities and health through the app. \n",
    "\n",
    "The data engineering team is responsible for making sure all the pet data from thousands of users is organized and safe, so pet owners can get tips to keep their pets happy and healthy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b5c7e-84a1-47aa-91e5-69237d0f7768",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "HappyPaws has collected three datasets over the past year: \n",
    " - \"pet_activities.csv\" which logs daily activities of pets, \n",
    " - \"pet_health.csv\" which records vet visits and health issues, and \n",
    " - \"users.csv\" which contains information about the pet owners. \n",
    "\n",
    "Each dataset contains unique identifiers for pets and/or their owners. \n",
    "\n",
    "The engineers developing the app currently write code to cross reference all of these data sources. \n",
    "\n",
    "They want to make things easier by having a single table with all data included.\n",
    "\n",
    "Your manager has asked you to write a Python function that cleans and merges these datasets into a single dataset. \n",
    "\n",
    "The final dataset should provide a comprehensive view of each pet's activities, health records, and owner information. \n",
    "\n",
    "- To test your code, your manager will run only the code `all_pet_data('pet_activities.csv', 'pet_health.csv', 'users.csv')`\n",
    "- Your `all_pet_data()` function must return a DataFrame, with columns as described below.\n",
    "- All columns must accurately match the descriptions provided below, including names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f8345-891c-4a4a-a37c-f89d0a22f997",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data that has been provided has the following structure\n",
    "\n",
    "![image](image.png)\n",
    "\n",
    "The function that you write must return data as described below. There should be a unique row for each activity/health visit. \n",
    "\n",
    "Where missing values are permitted, they should be in the default Python format.\n",
    "\n",
    "|Column Name | Description |\n",
    "|-------|-------|\n",
    "| pet_id | Unique identifier for each pet. There should not be any missing values.|\n",
    "| date | The date of the activity recorded or the date of the health visit, in date format. There should not be any missing values.|\n",
    "| activity_type | The type of activity, one of 'Walking', 'Playing', 'Resting' or for rows that relate to a health visit, the value 'Health'. Missing values are permitted.|\n",
    "| duration_minutes | The duration of the activity in minutes. For rows that relate to health visits, this should be 0. Missing values for other activities are permitted.|\n",
    "| issue | The health issue identified or check-up note. For rows that relate to activities, this should be a missing value. Missing values for health activities are permitted.|\n",
    "| resolution | The outcome or advice given for the issue. For rows that relate to activities, this should be a missing value. Missing values for health activities are permitted.|\n",
    "| owner_id | Unique identifier for the pet owner. All pets must have an owner.|\n",
    "| owner_age_group | The age group of the owner (e.g., 18-25, 26-35, etc.). Missing values are permitted.|\n",
    "| pet_type | The type of pet (e.g., Dog, Cat). Missing values are permitted.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c442fa0",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d93d6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1f8d38f6-dcbc-4fb4-a70a-8e2ca60c6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33980f",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cf4f036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load databases\n",
    "\n",
    "def load_dbs(*filenames: str):\n",
    "    \"\"\"Takes supplied filenames and returns a list of dataframes \\\n",
    "    \n",
    "    The list order is 'activities', 'health', 'users'\n",
    "\n",
    "    Returns:\n",
    "        list: a list of dataframes\n",
    "    \"\"\"\n",
    "    names = ['activities', 'health', 'users']\n",
    "    dataframes = []\n",
    "    for name in names:\n",
    "        result = list(filter(lambda filename: name in filename, filenames))\n",
    "        if not result:\n",
    "            raise ValueError(f'None of the supplied filenames contains \"{name}\"')\n",
    "        if len(result) > 1:\n",
    "            raise ValueError(f'More than one filename returned containing \"{name}\"')\n",
    "        dataframes.append(pd.read_csv(result[0]))\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16533e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge databases\n",
    "\n",
    "def merge_dbs(*dfs: pd.DataFrame, method='inner'):\n",
    "    \"\"\"Merges the supplied databases \\\n",
    "    \n",
    "    Expects databases to be two or more of \"pet activities\", \"pet health\", and \"users\"\n",
    "\n",
    "    Args:\n",
    "        method (str, optional): The method to use for joining any database to \"users\". Defaults to 'inner'.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Raised if fewer than 2 valid dataframes are supplied\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: the resulting merged dataframe\n",
    "    \"\"\"\n",
    "    # Identify dataframes\n",
    "    activities = list(filter(lambda x: 'activity_type' in x.columns, dfs))\n",
    "    health = list(filter(lambda x: 'issue' in x.columns, dfs))\n",
    "    users = list(filter(lambda x: 'owner_id' in x.columns, dfs))\n",
    "\n",
    "    # Check for at least two valid databases\n",
    "    if sum([bool(x) for x in [activities, health, users]]) < 2:\n",
    "        raise ValueError('Must supply at least two valid dataframes')\n",
    "\n",
    "    # Rename columns to simplify merge\n",
    "    if health:\n",
    "        health[0].rename(columns={'visit_date': 'date'}, inplace=True)\n",
    "\n",
    "    # Merge dataframes\n",
    "    if activities and health:\n",
    "        activities = pd.concat([activities[0], health[0]], ignore_index=True)\n",
    "    elif health:\n",
    "        activities = health[0]\n",
    "    else:\n",
    "        activities = activities[0]\n",
    "    if users:\n",
    "        merged_df = pd.merge(activities, users[0], on='pet_id', how=method)\n",
    "    else:\n",
    "        merged_df = activities\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "def clean_data(df: pd.DataFrame):\n",
    "    \"\"\"Checks for specific columns in the dataframe and cleans them\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): the dataframe to be cleaned\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: the cleaned dataframe\n",
    "    \"\"\"\n",
    "    tdf = df.copy()\n",
    "\n",
    "    # Drop records missing \"pet_id\", \"owner_id\", or \"date\"\n",
    "\n",
    "    tdf.dropna(subset=['pet_id', 'date', 'owner_id'], inplace=True)\n",
    "\n",
    "    # Strip leading and trailing whitespace from columns with strings\n",
    "    for column in ['activity_type', 'issue', 'resolution', 'owner_age_group', 'pet_type']:\n",
    "        if column in tdf.columns:\n",
    "            tdf[column] = tdf[column].str.strip()\n",
    "    \n",
    "    # Change \"date\" datatype\n",
    "    if 'date' in tdf.columns:\n",
    "        tdf.date = pd.to_datetime(tdf.date, errors='coerce')\n",
    "\n",
    "    # Assign \"Health\" to health activities\n",
    "    if 'issue' in tdf.columns:\n",
    "        tdf.loc[~df.issue.isna(), 'activity_type'] = 'Health'  \n",
    "\n",
    "    # Clean values for 'activity_type': \"Playing\", \"Walking\", \"Resting\"\n",
    "    if 'activity_type' in tdf.columns:\n",
    "        for activity in ['Play', 'Walk', 'Rest']:\n",
    "            tdf.activity_type = tdf.activity_type.str.replace(fr'^{activity}$', f'{activity}ing', regex=True)\n",
    "        tdf.activity_type = tdf.activity_type.astype('category')  \n",
    "\n",
    "    # Assign 0 to \"duration_minutes\" for health records and convert datatype\n",
    "    if 'duration_minutes' in tdf.columns:\n",
    "        tdf.loc[tdf.activity_type == 'Health', 'duration_minutes'] = 0\n",
    "        tdf.loc[tdf.duration_minutes == '-', 'duration_minutes'] = np.nan\n",
    "        tdf.duration_minutes = tdf.duration_minutes.astype('float')\n",
    "\n",
    "    # Assign NaN for \"issue\", if missing, and change datatype to \"category\"\n",
    "    if 'issue' in tdf.columns:\n",
    "        tdf.loc[tdf.issue.isna(), 'issue'] = np.nan\n",
    "        tdf.issue = tdf.issue.astype('category')\n",
    "\n",
    "    # Assign NaN for \"resolution\", if missing, and change datatype to \"category\"\n",
    "    if 'resolution' in tdf.columns:\n",
    "        tdf.loc[tdf.resolution.isna(), 'resolution'] = np.nan\n",
    "        tdf.resolution = tdf.resolution.astype('category')\n",
    "\n",
    "    # Change \"owner_age_group\" datatype to \"category\" and assign NaN, if missing\n",
    "    if 'owner_age_group' in tdf.columns:\n",
    "        tdf.loc[tdf.owner_age_group.isna(), 'owner_age_group'] = np.nan\n",
    "        # tdf.owner_age_group = tdf.owner_age_group.astype('category')\n",
    "\n",
    "    # Change \"pet_type\" datatype to \"category\" and assign NaN, if missing\n",
    "    if 'pet_type' in tdf.columns:\n",
    "        tdf.loc[tdf.pet_type.isna(), 'pet_type'] = np.nan\n",
    "        tdf.pet_type = tdf.pet_type.astype('category')\n",
    "\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114eab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data\n",
    "def sort_data(df: pd.DataFrame):\n",
    "    \"\"\"Orders the columns of the data and sorts the records\n",
    "     Records are sorted by `pet_id`, `date`, `owner_id`, and `activity_type`\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to be sorted\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: a dataframe that has been ordered\n",
    "    \"\"\"\n",
    "    col_order = ['pet_id', 'date', 'activity_type', 'duration_minutes', 'issue', 'resolution',\t'owner_id',\t'owner_age_group', 'pet_type']\n",
    "    cols = [x for x in col_order if x in df.columns]\n",
    "    sorted_df = df.loc[:, cols].sort_values(['pet_id', 'date', 'owner_id', 'activity_type']).reset_index(drop=True)\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pet data (final function)\n",
    "\n",
    "def all_pet_data(activities: str, health: str, users: str, merge: str = 'left', sort: bool = False):\n",
    "    \"\"\"Merges and cleans data from the \"pet activities\", \"pet health\", and \"users\" databases\n",
    "\n",
    "    Args:\n",
    "        activities (str): the \"activities\" CSV file\n",
    "        health (str): the \"health\" CSV file\n",
    "        users (str): the \"users\" CSV file\n",
    "        merge (str): the type of merge to be performed between any database and \"users\". Defaults to 'left'.\n",
    "        sort (bool): whether to sort rows and columns of the resulting dataframe. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: a DataFrame of cleaned and merged databases\n",
    "    \"\"\"\n",
    "    df_list = load_dbs(activities, health, users)   # Load\n",
    "    merge_df = merge_dbs(*df_list, method=merge)    # Merge\n",
    "    clean_df = clean_data(merge_df)                 # Clean\n",
    "    if sort:                                        # Sort\n",
    "        return sort_data(clean_df)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fb3e8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "\n",
    "def test_function(activities: str, health: str, users: str):\n",
    "\n",
    "    with open (activities, 'r') as file:\n",
    "        pa_df=pd.read_csv(file, parse_dates=['date'])\n",
    "\n",
    "    with open (health, 'r') as file:\n",
    "        ph_df=pd.read_csv(file, parse_dates=['visit_date'])\n",
    "\n",
    "    with open (users, 'r') as file:\n",
    "        u_df=pd.read_csv(file)\n",
    "\n",
    "    pa_df = pa_df.dropna(subset=['pet_id', 'date'])\n",
    "    pa_df['activity_type'] = pa_df['activity_type'].str.strip()\n",
    "    pa_df['activity_type'] = pa_df['activity_type'].replace({\"Play\":\"Playing\", \"Walk\":\"Walking\", \"Rest\":\"Resting\"})\n",
    "    pa_df['issue'] = pa_df['issue'] = np.nan\n",
    "    pa_df['resolution'] = np.nan\n",
    "\n",
    "    ph_df = ph_df.rename(columns={'visit_date':'date'})\n",
    "    ph_df = ph_df.dropna(subset=['pet_id', 'date'])\n",
    "    ph_df['issue'] = ph_df['issue'].str.strip()\n",
    "    ph_df['resolution'] = ph_df['resolution'].str.strip()\n",
    "    ph_df['activity_type'] = 'Health'\n",
    "    ph_df['duration_minutes'] = 0\n",
    "\n",
    "    u_df = u_df.dropna(subset=['owner_id'])\n",
    "    u_df['owner_age_group'] = u_df['owner_age_group'].str.strip()\n",
    "    u_df['pet_type'] = u_df['pet_type'].str.strip()\n",
    "\n",
    "    pa_ph_df = pd.concat([pa_df,ph_df], axis=0, ignore_index=True)\n",
    "\n",
    "    final_df = pa_ph_df.merge(u_df, on='pet_id', how='left')\n",
    "\n",
    "    final_df['duration_minutes'] = final_df['duration_minutes'].replace('-', np.nan)\n",
    "\n",
    "    #final_df['activity_type'] = final_df['activity_type'].astype('category')\n",
    "    final_df['duration_minutes'] = final_df['duration_minutes'].astype(float)\n",
    "    #final_df['issue'] = final_df['issue'].astype('category')\n",
    "    #final_df['resolution'] = final_df['resolution'].astype('category')\n",
    "    #final_df['owner_age_group'] = final_df['owner_age_group'].astype('category')\n",
    "    #final_df['pet_type'] = final_df['pet_type'].astype('category')\n",
    "\n",
    "    #final_df.info()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e5574385",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DataFrame.iloc[:, 0] (column name=\"pet_id\") are different\n\nDataFrame.iloc[:, 0] (column name=\"pet_id\") values are different (99.73376 %)\n[index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n[left]:  [9930, 3040, 2381, 3936, 8989, 627, 3132, 9988, 3735, 3035, 4339, 3686, 9230, 3223, 3612, 7393, 1001, 7267, 6725, 3225, 4238, 1956, 2058, 6332, 9689, 9419, 2178, 3001, 9689, 9769, 5468, 2549, 7956, 5747, 1382, 2869, 5975, 8805, 8244, 8007, 6103, 2882, 1297, 850, 1640, 5071, 4583, 5062, 9305, 1585, 8285, 8989, 7818, 427, 9223, 1925, 7030, 9367, 3088, 2342, 9539, 4150, 4001, 1906, 585, 8226, 579, 7022, 3846, 850, 5984, 7716, 4480, 3821, 6939, 6609, 5334, 9407, 1173, 3936, 8631, 4937, 3001, 2528, 7642, 579, 8840, 5919, 9466, 7117, 306, 8840, 309, 3530, 7296, 9357, 4307, 8149, 83, 7818, ...]\n[right]: [9, 9, 9, 9, 9, 83, 83, 83, 83, 83, 83, 121, 121, 150, 150, 209, 209, 209, 215, 215, 217, 217, 217, 217, 217, 236, 236, 236, 239, 239, 239, 239, 248, 248, 249, 249, 306, 306, 309, 309, 309, 309, 309, 309, 309, 309, 337, 337, 337, 337, 337, 337, 379, 427, 427, 427, 428, 454, 473, 473, 473, 500, 500, 503, 503, 503, 516, 532, 532, 538, 538, 538, 538, 542, 542, 542, 542, 556, 556, 556, 556, 579, 579, 579, 579, 585, 585, 585, 585, 601, 601, 601, 601, 627, 627, 627, 627, 627, 637, 637, ...]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[263]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assert_frame_equal\n\u001b[32m      7\u001b[39m assert_frame_equal(df_left, df_inner)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_left\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 3 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NextCloud\\data science\\projects\\.venv\\Lib\\site-packages\\pandas\\_testing\\asserters.py:690\u001b[39m, in \u001b[36massert_numpy_array_equal.<locals>._raise\u001b[39m\u001b[34m(left, right, err_msg)\u001b[39m\n\u001b[32m    688\u001b[39m     diff = diff * \u001b[32m100.0\u001b[39m / left.size\n\u001b[32m    689\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m values are different (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.round(diff,\u001b[38;5;250m \u001b[39m\u001b[32m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m %)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[43mraise_assert_detail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(err_msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NextCloud\\data science\\projects\\.venv\\Lib\\site-packages\\pandas\\_testing\\asserters.py:620\u001b[39m, in \u001b[36mraise_assert_detail\u001b[39m\u001b[34m(obj, message, left, right, diff, first_diff, index_values)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    618\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[31mAssertionError\u001b[39m: DataFrame.iloc[:, 0] (column name=\"pet_id\") are different\n\nDataFrame.iloc[:, 0] (column name=\"pet_id\") values are different (99.73376 %)\n[index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n[left]:  [9930, 3040, 2381, 3936, 8989, 627, 3132, 9988, 3735, 3035, 4339, 3686, 9230, 3223, 3612, 7393, 1001, 7267, 6725, 3225, 4238, 1956, 2058, 6332, 9689, 9419, 2178, 3001, 9689, 9769, 5468, 2549, 7956, 5747, 1382, 2869, 5975, 8805, 8244, 8007, 6103, 2882, 1297, 850, 1640, 5071, 4583, 5062, 9305, 1585, 8285, 8989, 7818, 427, 9223, 1925, 7030, 9367, 3088, 2342, 9539, 4150, 4001, 1906, 585, 8226, 579, 7022, 3846, 850, 5984, 7716, 4480, 3821, 6939, 6609, 5334, 9407, 1173, 3936, 8631, 4937, 3001, 2528, 7642, 579, 8840, 5919, 9466, 7117, 306, 8840, 309, 3530, 7296, 9357, 4307, 8149, 83, 7818, ...]\n[right]: [9, 9, 9, 9, 9, 83, 83, 83, 83, 83, 83, 121, 121, 150, 150, 209, 209, 209, 215, 215, 217, 217, 217, 217, 217, 236, 236, 236, 239, 239, 239, 239, 248, 248, 249, 249, 306, 306, 309, 309, 309, 309, 309, 309, 309, 309, 337, 337, 337, 337, 337, 337, 379, 427, 427, 427, 428, 454, 473, 473, 473, 500, 500, 503, 503, 503, 516, 532, 532, 538, 538, 538, 538, 542, 542, 542, 542, 556, 556, 556, 556, 579, 579, 579, 579, 585, 585, 585, 585, 601, 601, 601, 601, 627, 627, 627, 627, 627, 637, 637, ...]"
     ]
    }
   ],
   "source": [
    "filelist = ['pet_activities.csv', 'pet_health.csv', 'users.csv']\n",
    "df_left = all_pet_data(*filelist)\n",
    "df_inner = all_pet_data(filelist[0], filelist[1], filelist[2], 'inner')\n",
    "test_df = test_function(*filelist)\n",
    "\n",
    "from pandas.testing import assert_frame_equal\n",
    "assert_frame_equal(df_left, df_inner)\n",
    "assert_frame_equal(test_df, df_left)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
